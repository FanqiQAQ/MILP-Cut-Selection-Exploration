{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5de5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "from pyscipopt import Model, Sepa, Eventhdlr, SCIP_RESULT, SCIP_PARAMSETTING, SCIP_EVENTTYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8475748a",
   "metadata": {},
   "source": [
    "### Feature Extraction (Based on Table 7 of the paper)\n",
    "The goal is to convert a raw Cutting Plane (a row in the SCIP matrix) into a fixed-size vector (dimension = 13) for the Reinforcement learning policy.\n",
    "The 13 features are categorized into four groups:\n",
    "1.  **Cut Coefficients Statistics (4 dims):** Basic statistics (mean, max, min, std) of the constraint coefficients.\n",
    "2.  **Objective Coefficients Statistics (4 dims):** Statistics of the objective function coefficients $c$ corresponding to the variables involved in the cut.\n",
    "3.  **Geometric & Structural Features (4 dims):**\n",
    "     * **Parallelism:** Cosine similarity between the cut's normal vector and the objective function gradient.\n",
    "     * **Efficacy:** Euclidean distance from the current LP solution to the cut hyperplane.\n",
    "     * **Support (Sparsity):** Percentage of non-zero coefficients.\n",
    "     * **Integral Support:** Percentage of integer variables involved in the cut.\n",
    "4.  **Violation Measure (1 dim):**\n",
    "     * **Normalized Violation:** How much the current LP solution violates this cut (normalized by the RHS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e091f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, row):\n",
    "    # Get the variables (cols) and their coefficients (vals) in this cut\n",
    "    cols = row.getCols()\n",
    "    vals = row.getVals()\n",
    "    cut_coeffs = np.array(vals)\n",
    "    # Gather objective function coefficients for the involved variable\n",
    "    obj_coeffs = []\n",
    "    integral_var_count = 0\n",
    "    for col in cols:\n",
    "        var = col.getVar() \n",
    "        obj_coeffs.append(var.getObj())\n",
    "        if var.vtype() in [\"BINARY\", \"INTEGER\", \"IMPLINT\"]:\n",
    "            integral_var_count += 1\n",
    "    obj_coeffs = np.array(obj_coeffs)\n",
    "    \n",
    "    # 1-4: Cut Coefficients Statistics\n",
    "    f_cut_mean = np.mean(cut_coeffs)\n",
    "    f_cut_max  = np.max(cut_coeffs)\n",
    "    f_cut_min  = np.min(cut_coeffs)\n",
    "    f_cut_std  = np.std(cut_coeffs)\n",
    "    \n",
    "    # 5-8: Objective Coefficients Statistics\n",
    "    if len(obj_coeffs) > 0:\n",
    "        f_obj_mean = np.mean(obj_coeffs)\n",
    "        f_obj_max  = np.max(obj_coeffs)\n",
    "        f_obj_min  = np.min(obj_coeffs)\n",
    "        f_obj_std  = np.std(obj_coeffs)\n",
    "    else:\n",
    "        f_obj_mean, f_obj_max, f_obj_min, f_obj_std = 0.0, 0.0, 0.0, 0.0\n",
    "    \n",
    "    # 9: Parallelism\n",
    "    norm_cut = np.linalg.norm(cut_coeffs)\n",
    "    norm_obj = np.linalg.norm(obj_coeffs)\n",
    "    \n",
    "    if norm_cut > 1e-9 and norm_obj > 1e-9:\n",
    "        f_parallelism = np.dot(cut_coeffs, obj_coeffs) / (norm_cut * norm_obj)\n",
    "    else:\n",
    "        f_parallelism = 0.0\n",
    "    \n",
    "    # 10: Efficacy\n",
    "    f_efficacy = model.getCutEfficacy(row)\n",
    "    \n",
    "    # 11: Support\n",
    "    n_vars_total = model.getNVars()\n",
    "    f_support = len(cut_coeffs) / (n_vars_total + 1e-5)\n",
    "    \n",
    "    # 12: Integral Support\n",
    "    f_int_support = integral_var_count / (len(cut_coeffs) + 1e-5)\n",
    "    \n",
    "    # 13: Normalized Violation\n",
    "    # max(0, (Activity - RHS) / |RHS|)\n",
    "    activity = model.getRowActivity(row)\n",
    "    rhs = row.getRhs()\n",
    "    denom = abs(rhs) if abs(rhs) > 1e-9 else 1.0\n",
    "    f_norm_violation = max(0.0, (activity - rhs) / denom)\n",
    "    \n",
    "   \n",
    "    features = np.array([\n",
    "        f_cut_mean, f_cut_max, f_cut_min, f_cut_std,       # 1-4\n",
    "        f_obj_mean, f_obj_max, f_obj_min, f_obj_std,       # 5-8\n",
    "        f_parallelism,                                     # 9\n",
    "        f_efficacy,                                        # 10\n",
    "        f_support,                                         # 11\n",
    "        f_int_support,                                     # 12\n",
    "        f_norm_violation                                   # 13\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707fec3",
   "metadata": {},
   "source": [
    "### Reward Monitor\n",
    "\n",
    "SCIP operates asynchronously:\n",
    "1.  The **Separator** adds cuts (Action). At this exact moment, the LP has *not* been re-solved yet, so the Dual Bound is unchanged.\n",
    "2.  SCIP runs the **Simplex Methods** to solve the new LP.\n",
    "3.  The **Event Handler** (this class) is triggered after the LP is solved. This is the first moment we can observe the effect of the cuts.\n",
    " \n",
    "The Logic\n",
    " * **Event:** Listens for `SCIP_EVENTTYPE.LPSOLVED`.\n",
    " * **Metric:** Tracks the **Dual Bound** (Linear Relaxation Objective Value).\n",
    " * **Reward Calculation:** For a maximization problem (like MIS), the Dual Bound is an Upper Bound. A \"good\" cut tightens the relaxation, causing the Upper Bound to **decrease**.\n",
    "      $$Reward = \\text{Old Dual Bound} - \\text{New Dual Bound}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d4c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardMonitor(Eventhdlr):    \n",
    "    def __init__(self):\n",
    "        # Stores the collected transitions: (state, action, reward)\n",
    "        self.data = []\n",
    "        \n",
    "        # A temporary buffer to hold the (State, Action) pair from the Separator\n",
    "        # until the LP is solved and the Reward can be calculated.\n",
    "        # Structure: (state_features, action_indices, old_dual_bound)\n",
    "        self.pending_transition = None \n",
    "\n",
    "    def eventinit(self):\n",
    "        self.model.catchEvent(SCIP_EVENTTYPE.LPSOLVED, self)\n",
    "\n",
    "    def eventexit(self):\n",
    "        self.model.dropEvent(SCIP_EVENTTYPE.LPSOLVED, self)\n",
    "\n",
    "    def eventexec(self, event):\n",
    "        # 1. Get the current Dual Bound (LP Objective Value)\n",
    "        # Note: For Maximization problems (like MIS), the LP relaxation provides an Upper Bound.\n",
    "        # We want to minimize this Upper Bound (tighten the relaxation).\n",
    "        current_db = self.model.getLPObjVal()\n",
    "        \n",
    "        # 2. Check if there is a pending action waiting to be evaluated\n",
    "        if self.pending_transition:\n",
    "            # Unpack the data stored by the Separator\n",
    "            state, action, old_db = self.pending_transition\n",
    "            \n",
    "            # 3. Calculate Reward\n",
    "            # Logic: Improvement = Old Bound - New Bound\n",
    "            # If the bound decreased (got tighter), the difference is positive (Reward > 0).\n",
    "            reward = 0.0\n",
    "            \n",
    "            # Filter out cases where the initial bound is infinite (first LP solve)\n",
    "            if old_db < 1e19: \n",
    "                reward = old_db - current_db\n",
    "            \n",
    "            # 4. Store the Experience\n",
    "            # We scale the reward by 10.0 to make the numerical values larger for easier Gradient Descent.\n",
    "            # Only store the transition if the action has been evaluated.\n",
    "            self.data.append({\n",
    "                'state': state,          # The features of candidate cuts\n",
    "                'action': action,        # The indices of selected cuts\n",
    "                'reward': reward * 10.0  # The calculated improvement\n",
    "            })\n",
    "            \n",
    "            # 5. Clear the buffer\n",
    "            self.pending_transition = None\n",
    "            \n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dfb5bb",
   "metadata": {},
   "source": [
    "### Random Data Separator\n",
    "\n",
    "This class implements the **Separator** component of the SCIP Reinforcement Learning loop. \n",
    "\n",
    "1.  **Simulated Cut Generation:**\n",
    "    * **Challenge:** The `PySCIPOpt` interface does not natively support intercepting the raw \"Global Cut Pool\" generated by SCIP's internal separators (like Gomory or MIR) before they are added.\n",
    "    * **Solution:** For this experiment, we only simulate the generation process. We identify fractional variables (e.g., $x = 0.4$) and manually generate simple \"Bound Cuts\" (e.g., $x \\le 0$).\n",
    "\n",
    "2.  **Random Policy for Exploration:**\n",
    "    To train a robust RL agent, we need a diverse dataset covering the State-Action space. This separator implements a Random Policy:\n",
    "    * **Order:** It randomly shuffles the cut list, allowing the model to learn that cut order matters (a key finding of the paper).\n",
    "    * **Ratio:** It randomly selects a subset size (from 1 to $N$), allowing the model to learn how many cuts to select.\n",
    "\n",
    "### Workflow\n",
    "1.  **Generate:** Create candidate cuts based on fractional variables.\n",
    "2.  **Perceive:** Extract 13-dim features for each candidate ($S_t$).\n",
    "3.  **Act:** Randomly shuffle and select a subset of cuts ($A_t$).\n",
    "4.  **Execute:** Add the selected cuts to the SCIP solver.\n",
    "5.  **Handoff:** Pass the State and Action to the `RewardMonitor` to await the reward signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb28f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataSepa(Sepa):\n",
    "    def __init__(self, monitor):\n",
    "        self.monitor = monitor\n",
    "    # PART A: Candidate Cut Generation (SIMULATION)\n",
    "    def sepaexeclp(self):\n",
    "        model = self.model\n",
    "        # 1. Identify fractional variables (candidates for separation/branching)\n",
    "        # We look for variables x where 0 < x < 1 (in binary problems)\n",
    "        vars = model.getVars()\n",
    "        fractional_vars = [v for v in vars if 0.01 < model.getSolVal(None, v) < 0.99]\n",
    "        \n",
    "        candidates = []\n",
    "        if fractional_vars:\n",
    "            # Heuristic: Randomly select up to 10 fractional variables to generate cuts for\n",
    "            n_gen = min(10, len(fractional_vars))\n",
    "            target_vars = random.sample(fractional_vars, n_gen)\n",
    "            \n",
    "            for i, v in enumerate(target_vars):\n",
    "                # Simulate a cut: \n",
    "                # If x is closer to 0, add cut: x <= 0 (Logic: x should probably be 0)\n",
    "                # If x is closer to 1, add cut: x >= 1 (Logic: x should probably be 1)\n",
    "                # Note: These resemble \"local branching\" constraints.\n",
    "                val = model.getSolVal(None, v)\n",
    "                cut_name = f\"sim_cut_{i}\"\n",
    "                \n",
    "                if val < 0.5:\n",
    "                    # Create row: 1.0 * v <= 0.0\n",
    "                    row = model.createEmptyRowSepa(self, cut_name, lhs=None, rhs=0.0)\n",
    "                    model.addVarToRow(row, v, 1.0)\n",
    "                else:\n",
    "                    # Create row: 1.0 * v >= 1.0\n",
    "                    row = model.createEmptyRowSepa(self, cut_name, lhs=1.0, rhs=None)\n",
    "                    model.addVarToRow(row, v, 1.0)\n",
    "                \n",
    "                # Validity Check: Only add cuts that are efficacious (actually cut off the current LP solution)\n",
    "                if model.isCutEfficacious(row):\n",
    "                    candidates.append(row)\n",
    "        \n",
    "        # If no valid cuts could be generated, exit\n",
    "        if not candidates:\n",
    "            return {\"result\": SCIP_RESULT.DIDNOTFIND}\n",
    "        # PART B: Feature Extraction\n",
    "        # Convert the physical Row objects into 13-dimensional feature vectors\n",
    "        state_features = [get_features(model, c) for c in candidates]\n",
    "        # PART C: Random Policy Execution (Action A_t)\n",
    "        # Random Policy is used here to explore the state-action space.\n",
    "        \n",
    "        # 1. Randomize Order (Addressing \"Order Matters\" from the paper)\n",
    "        indices = list(range(len(candidates)))\n",
    "        random.shuffle(indices)\n",
    "        \n",
    "        # 2. Randomize Selection Ratio (Addressing \"How many cuts to select\")\n",
    "        # We randomly choose to apply between 1 and all candidates.\n",
    "        n_select = random.randint(1, len(candidates))\n",
    "        selected_indices = indices[:n_select]\n",
    "        \n",
    "        # PART D: Apply Cuts & Suspend\n",
    "        # Apply the selected cuts to the SCIP model\n",
    "        for idx in selected_indices:\n",
    "            model.addCut(candidates[idx])\n",
    "            \n",
    "        # Capture the current objective value (to calculate reward later)\n",
    "        current_db = model.getLPObjVal()\n",
    "        \n",
    "        # Handoff to RewardMonitor: Store (State, Action, Old_Dual_Bound)\n",
    "        # The monitor will calculate the Reward after SCIP re-solves the LP.\n",
    "        self.monitor.pending_transition = (state_features, selected_indices, current_db)\n",
    "        \n",
    "        return {\"result\": SCIP_RESULT.SEPARATED}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f37cd",
   "metadata": {},
   "source": [
    "### Main Program\n",
    "\n",
    "This is the entry point of the script. It orchestrates the entire data collection process by generating a series of diverse problem instances and letting the **Random Separator** interact with them.\n",
    "\n",
    "### Workflow per Episode:\n",
    "1.  **Generate Instance:** Creates a new random graph (Barabasi-Albert model) and formulates the **Maximum Independent Set (MIS)** problem.\n",
    "2.  **Configure Solver:** * `separating/maxrounds = 5`: Limits the solving time per instance to keep data collection fast.\n",
    "    * `Presolve = OFF`: Disables SCIP's built-in simplification. This is critical to ensure the problem remains \"hard enough\" for the agent to learn meaningful cut selection strategies.\n",
    "3.  **Attach Plugins:** Registers our custom `RandomDataSepa` and `RewardMonitor` into the SCIP environment.\n",
    "4.  **Solve & Collect:** Runs the optimization. The plugins automatically intercept the process, generate cuts, record features/actions, and calculate rewards.\n",
    "5.  **Save:** Aggregates all transition data `(s, a, r)` into a pickle file for offline training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2591fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_collection():\n",
    "    NUM_EPISODES = 60   # Number of graphs\n",
    "    NODES = 70          # Graph size\n",
    "    OUTPUT_FILE = \"mis_data_final.pkl\"\n",
    "    \n",
    "    all_dataset = []\n",
    "    print(f\">>> [Step 1] Starting Data Collection ({NUM_EPISODES} episodes)...\")\n",
    "\n",
    "    for i in range(NUM_EPISODES):\n",
    "        # 1. Generate Problem\n",
    "        g = nx.gnp_random_graph(NODES, 0.15,seed=i)\n",
    "        model = Model(f\"MIS_{i}\")\n",
    "        model.hideOutput()\n",
    "        \n",
    "        x = {n: model.addVar(vtype=\"B\") for n in g.nodes()}\n",
    "        for u, v in g.edges():\n",
    "            model.addCons(x[u] + x[v] <= 1)\n",
    "        model.setObjective(sum(x.values()), \"maximize\")\n",
    "        \n",
    "        # 2. Setup Environment\n",
    "        model.setIntParam(\"separating/maxrounds\", 5)\n",
    "        model.setPresolve(SCIP_PARAMSETTING.OFF)\n",
    "        \n",
    "        # 3. Attach Plugins\n",
    "        monitor = RewardMonitor()\n",
    "        model.includeEventhdlr(monitor, \"RewardMonitor\", \"\")\n",
    "        sepa = RandomDataSepa(monitor)\n",
    "        model.includeSepa(sepa, \"RandomSepa\", \"\", priority=100000, freq=1)\n",
    "        \n",
    "        # 4. Solve\n",
    "        model.optimize()\n",
    "        \n",
    "        # 5. Collect\n",
    "        if monitor.data:\n",
    "            all_dataset.extend(monitor.data)\n",
    "            \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"  Progress: Episode {i+1}/{NUM_EPISODES}, Collected Samples: {len(all_dataset)}\")\n",
    "\n",
    "    print(f\"\\n>>> Done! Saving {len(all_dataset)} samples to '{OUTPUT_FILE}'\")\n",
    "    with open(OUTPUT_FILE, \"wb\") as f:\n",
    "        pickle.dump(all_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5688c24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Step 1] Starting Data Collection (60 episodes)...\n",
      "  Progress: Episode 10/60, Collected Samples: 10\n",
      "  Progress: Episode 20/60, Collected Samples: 20\n",
      "  Progress: Episode 30/60, Collected Samples: 30\n",
      "  Progress: Episode 40/60, Collected Samples: 40\n",
      "  Progress: Episode 50/60, Collected Samples: 50\n",
      "  Progress: Episode 60/60, Collected Samples: 60\n",
      "\n",
      ">>> Done! Saving 60 samples to 'mis_data_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "run_data_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2879e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning: mis_data_final.pkl ...\n",
      "   0 outliers detected\n",
      "   60 samples remained\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Step 1.5: Data Cleaning\n",
    "# \n",
    "# We detected some samples with massive negative rewards (e.g., -1e21). \n",
    "# This indicates SCIP returned \"Infinity\" for the new bound, likely due to numerical resets.\n",
    "# We must clip these rewards to 0.0 to prevent gradient explosion during training.\n",
    "\n",
    "# %%\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "FILE_NAME = \"mis_data_final.pkl\"\n",
    "\n",
    "# 1. 加载数据\n",
    "print(f\"cleaning: {FILE_NAME} ...\")\n",
    "with open(FILE_NAME, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "cleaned_count = 0\n",
    "valid_data = []\n",
    "\n",
    "for sample in dataset:\n",
    "    r = sample['reward']\n",
    "    \n",
    "    # 2. outlier detective\n",
    "    # reward < -1000\n",
    "    if r < -1000.0:\n",
    "        sample['reward'] = 0.0\n",
    "        cleaned_count += 1\n",
    "    \n",
    "    # 3. NaN\n",
    "    if not np.isnan(np.sum(sample['state'])):\n",
    "        valid_data.append(sample)\n",
    "\n",
    "# 3. save\n",
    "with open(FILE_NAME, \"wb\") as f:\n",
    "    pickle.dump(valid_data, f)\n",
    "\n",
    "print(f\"   {cleaned_count} outliers detected\")\n",
    "print(f\"   {len(valid_data)} samples remained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc536e",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a4ac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 60 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>n_Candidates</th>\n",
       "      <th>n_Selected</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Avg_Parallelism</th>\n",
       "      <th>Avg_Efficacy</th>\n",
       "      <th>Max_Efficacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID  n_Candidates  n_Selected  Reward  Avg_Parallelism  Avg_Efficacy  \\\n",
       "0          0            10           5     0.0             -1.0           0.5   \n",
       "1          1            10          10     0.0             -1.0           0.5   \n",
       "2          2            10           4     0.0             -1.0           0.5   \n",
       "3          3            10           3     0.0             -1.0           0.5   \n",
       "4          4            10           3     0.0             -1.0           0.5   \n",
       "\n",
       "   Max_Efficacy  \n",
       "0           0.5  \n",
       "1           0.5  \n",
       "2           0.5  \n",
       "3           0.5  \n",
       "4           0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 5 Best Moves):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>n_Candidates</th>\n",
       "      <th>n_Selected</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Avg_Parallelism</th>\n",
       "      <th>Avg_Efficacy</th>\n",
       "      <th>Max_Efficacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID  n_Candidates  n_Selected  Reward  Avg_Parallelism  Avg_Efficacy  \\\n",
       "0          0            10           5     0.0             -1.0           0.5   \n",
       "1          1            10          10     0.0             -1.0           0.5   \n",
       "2          2            10           4     0.0             -1.0           0.5   \n",
       "3          3            10           3     0.0             -1.0           0.5   \n",
       "4          4            10           3     0.0             -1.0           0.5   \n",
       "\n",
       "   Max_Efficacy  \n",
       "0           0.5  \n",
       "1           0.5  \n",
       "2           0.5  \n",
       "3           0.5  \n",
       "4           0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Describe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>n_Candidates</th>\n",
       "      <th>n_Selected</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Avg_Parallelism</th>\n",
       "      <th>Avg_Efficacy</th>\n",
       "      <th>Max_Efficacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.716667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.464249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.470790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.750000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.250000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample_ID  n_Candidates  n_Selected  Reward  Avg_Parallelism  \\\n",
       "count  60.000000          60.0   60.000000    60.0             60.0   \n",
       "mean   29.500000          10.0    6.716667     0.0             -1.0   \n",
       "std    17.464249           0.0    2.470790     0.0              0.0   \n",
       "min     0.000000          10.0    2.000000     0.0             -1.0   \n",
       "25%    14.750000          10.0    4.750000     0.0             -1.0   \n",
       "50%    29.500000          10.0    6.500000     0.0             -1.0   \n",
       "75%    44.250000          10.0    9.000000     0.0             -1.0   \n",
       "max    59.000000          10.0   10.000000     0.0             -1.0   \n",
       "\n",
       "       Avg_Efficacy  Max_Efficacy  \n",
       "count          60.0          60.0  \n",
       "mean            0.5           0.5  \n",
       "std             0.0           0.0  \n",
       "min             0.5           0.5  \n",
       "25%             0.5           0.5  \n",
       "50%             0.5           0.5  \n",
       "75%             0.5           0.5  \n",
       "max             0.5           0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = \"mis_data_final.pkl\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for i, sample in enumerate(dataset):\n",
    "    state = np.array(sample['state'])\n",
    "    action = sample['action']\n",
    "    reward = sample['reward']\n",
    "\n",
    "    if len(state) > 0:\n",
    "        avg_parallelism = np.mean(state[:, 8])\n",
    "        avg_efficacy = np.mean(state[:, 9])\n",
    "        avg_violation = np.mean(state[:, 12])\n",
    "        max_efficacy = np.max(state[:, 9])\n",
    "    else:\n",
    "        avg_parallelism, avg_efficacy, avg_violation, max_efficacy = 0, 0, 0, 0\n",
    "\n",
    "    table_data.append({\n",
    "        \"Sample_ID\": i,\n",
    "        \"n_Candidates\": len(state),       \n",
    "        \"n_Selected\": len(action), \n",
    "        \"Reward\": round(reward, 4),  \n",
    "        \"Avg_Parallelism\": round(avg_parallelism, 4), \n",
    "        \"Avg_Efficacy\": round(avg_efficacy, 4),  \n",
    "        \"Max_Efficacy\": round(max_efficacy, 4)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(table_data)\n",
    "\n",
    "print(f\"Total: {len(df)} samples\")\n",
    "\n",
    "\n",
    "display(df.head())\n",
    "print(\"\\n Top 5 Best Moves):\")\n",
    "display(df.sort_values(by=\"Reward\", ascending=False).head(5))\n",
    "\n",
    "print(\"\\nDescribe:\")\n",
    "display(df.describe())\n",
    "\n",
    "# 4.plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df['Reward'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Reward Distribution (Frequency of Bound Improvements)\")\n",
    "plt.xlabel(\"Reward Value (Dual Bound Reduction)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
